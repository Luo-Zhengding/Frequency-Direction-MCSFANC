{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef26052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified_ShufflenetV2_Frequency_DOA(\n",
      "  (bw2col): Sequential(\n",
      "    (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(8, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(10, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (mv2_base_conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (mv2_base_maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (mv2_base_fre_stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mv2_base_fre_stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mv2_base_doa_stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mv2_base_doa_stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avg_pool_fre): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (avg_pool_doa): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (freq_fc): Linear(in_features=96, out_features=7, bias=True)\n",
      "  (doa_fc): Linear(in_features=96, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 8, 64, 126]              16\n",
      "            Conv2d-2          [-1, 10, 64, 126]              90\n",
      "              ReLU-3          [-1, 10, 64, 126]               0\n",
      "            Conv2d-4           [-1, 3, 64, 126]              33\n",
      "              ReLU-5           [-1, 3, 64, 126]               0\n",
      "            Conv2d-6           [-1, 24, 32, 63]             648\n",
      "       BatchNorm2d-7           [-1, 24, 32, 63]              48\n",
      "              ReLU-8           [-1, 24, 32, 63]               0\n",
      "         MaxPool2d-9           [-1, 24, 16, 32]               0\n",
      "           Conv2d-10            [-1, 24, 8, 16]             216\n",
      "      BatchNorm2d-11            [-1, 24, 8, 16]              48\n",
      "           Conv2d-12            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-13            [-1, 24, 8, 16]              48\n",
      "             ReLU-14            [-1, 24, 8, 16]               0\n",
      "           Conv2d-15           [-1, 24, 16, 32]             576\n",
      "      BatchNorm2d-16           [-1, 24, 16, 32]              48\n",
      "             ReLU-17           [-1, 24, 16, 32]               0\n",
      "           Conv2d-18            [-1, 24, 8, 16]             216\n",
      "      BatchNorm2d-19            [-1, 24, 8, 16]              48\n",
      "           Conv2d-20            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-21            [-1, 24, 8, 16]              48\n",
      "             ReLU-22            [-1, 24, 8, 16]               0\n",
      " InvertedResidual-23            [-1, 48, 8, 16]               0\n",
      "           Conv2d-24            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-25            [-1, 24, 8, 16]              48\n",
      "             ReLU-26            [-1, 24, 8, 16]               0\n",
      "           Conv2d-27            [-1, 24, 8, 16]             216\n",
      "      BatchNorm2d-28            [-1, 24, 8, 16]              48\n",
      "           Conv2d-29            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-30            [-1, 24, 8, 16]              48\n",
      "             ReLU-31            [-1, 24, 8, 16]               0\n",
      " InvertedResidual-32            [-1, 48, 8, 16]               0\n",
      "           Conv2d-33            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-34            [-1, 24, 8, 16]              48\n",
      "             ReLU-35            [-1, 24, 8, 16]               0\n",
      "           Conv2d-36            [-1, 24, 8, 16]             216\n",
      "      BatchNorm2d-37            [-1, 24, 8, 16]              48\n",
      "           Conv2d-38            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-39            [-1, 24, 8, 16]              48\n",
      "             ReLU-40            [-1, 24, 8, 16]               0\n",
      " InvertedResidual-41            [-1, 48, 8, 16]               0\n",
      "           Conv2d-42            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-43            [-1, 24, 8, 16]              48\n",
      "             ReLU-44            [-1, 24, 8, 16]               0\n",
      "           Conv2d-45            [-1, 24, 8, 16]             216\n",
      "      BatchNorm2d-46            [-1, 24, 8, 16]              48\n",
      "           Conv2d-47            [-1, 24, 8, 16]             576\n",
      "      BatchNorm2d-48            [-1, 24, 8, 16]              48\n",
      "             ReLU-49            [-1, 24, 8, 16]               0\n",
      " InvertedResidual-50            [-1, 48, 8, 16]               0\n",
      "           Conv2d-51             [-1, 48, 4, 8]             432\n",
      "      BatchNorm2d-52             [-1, 48, 4, 8]              96\n",
      "           Conv2d-53             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-54             [-1, 48, 4, 8]              96\n",
      "             ReLU-55             [-1, 48, 4, 8]               0\n",
      "           Conv2d-56            [-1, 48, 8, 16]           2,304\n",
      "      BatchNorm2d-57            [-1, 48, 8, 16]              96\n",
      "             ReLU-58            [-1, 48, 8, 16]               0\n",
      "           Conv2d-59             [-1, 48, 4, 8]             432\n",
      "      BatchNorm2d-60             [-1, 48, 4, 8]              96\n",
      "           Conv2d-61             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-62             [-1, 48, 4, 8]              96\n",
      "             ReLU-63             [-1, 48, 4, 8]               0\n",
      " InvertedResidual-64             [-1, 96, 4, 8]               0\n",
      "           Conv2d-65             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-66             [-1, 48, 4, 8]              96\n",
      "             ReLU-67             [-1, 48, 4, 8]               0\n",
      "           Conv2d-68             [-1, 48, 4, 8]             432\n",
      "      BatchNorm2d-69             [-1, 48, 4, 8]              96\n",
      "           Conv2d-70             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-71             [-1, 48, 4, 8]              96\n",
      "             ReLU-72             [-1, 48, 4, 8]               0\n",
      " InvertedResidual-73             [-1, 96, 4, 8]               0\n",
      "           Conv2d-74             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-75             [-1, 48, 4, 8]              96\n",
      "             ReLU-76             [-1, 48, 4, 8]               0\n",
      "           Conv2d-77             [-1, 48, 4, 8]             432\n",
      "      BatchNorm2d-78             [-1, 48, 4, 8]              96\n",
      "           Conv2d-79             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-80             [-1, 48, 4, 8]              96\n",
      "             ReLU-81             [-1, 48, 4, 8]               0\n",
      " InvertedResidual-82             [-1, 96, 4, 8]               0\n",
      "           Conv2d-83             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-84             [-1, 48, 4, 8]              96\n",
      "             ReLU-85             [-1, 48, 4, 8]               0\n",
      "           Conv2d-86             [-1, 48, 4, 8]             432\n",
      "      BatchNorm2d-87             [-1, 48, 4, 8]              96\n",
      "           Conv2d-88             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-89             [-1, 48, 4, 8]              96\n",
      "             ReLU-90             [-1, 48, 4, 8]               0\n",
      " InvertedResidual-91             [-1, 96, 4, 8]               0\n",
      "           Conv2d-92             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-93             [-1, 48, 4, 8]              96\n",
      "             ReLU-94             [-1, 48, 4, 8]               0\n",
      "           Conv2d-95             [-1, 48, 4, 8]             432\n",
      "      BatchNorm2d-96             [-1, 48, 4, 8]              96\n",
      "           Conv2d-97             [-1, 48, 4, 8]           2,304\n",
      "      BatchNorm2d-98             [-1, 48, 4, 8]              96\n",
      "             ReLU-99             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-100             [-1, 96, 4, 8]               0\n",
      "          Conv2d-101             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-102             [-1, 48, 4, 8]              96\n",
      "            ReLU-103             [-1, 48, 4, 8]               0\n",
      "          Conv2d-104             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-105             [-1, 48, 4, 8]              96\n",
      "          Conv2d-106             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-107             [-1, 48, 4, 8]              96\n",
      "            ReLU-108             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-109             [-1, 96, 4, 8]               0\n",
      "          Conv2d-110             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-111             [-1, 48, 4, 8]              96\n",
      "            ReLU-112             [-1, 48, 4, 8]               0\n",
      "          Conv2d-113             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-114             [-1, 48, 4, 8]              96\n",
      "          Conv2d-115             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-116             [-1, 48, 4, 8]              96\n",
      "            ReLU-117             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-118             [-1, 96, 4, 8]               0\n",
      "          Conv2d-119             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-120             [-1, 48, 4, 8]              96\n",
      "            ReLU-121             [-1, 48, 4, 8]               0\n",
      "          Conv2d-122             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-123             [-1, 48, 4, 8]              96\n",
      "          Conv2d-124             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-125             [-1, 48, 4, 8]              96\n",
      "            ReLU-126             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-127             [-1, 96, 4, 8]               0\n",
      "AdaptiveAvgPool2d-128             [-1, 96, 1, 1]               0\n",
      "          Linear-129                    [-1, 7]             679\n",
      "          Conv2d-130            [-1, 24, 8, 16]             216\n",
      "     BatchNorm2d-131            [-1, 24, 8, 16]              48\n",
      "          Conv2d-132            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-133            [-1, 24, 8, 16]              48\n",
      "            ReLU-134            [-1, 24, 8, 16]               0\n",
      "          Conv2d-135           [-1, 24, 16, 32]             576\n",
      "     BatchNorm2d-136           [-1, 24, 16, 32]              48\n",
      "            ReLU-137           [-1, 24, 16, 32]               0\n",
      "          Conv2d-138            [-1, 24, 8, 16]             216\n",
      "     BatchNorm2d-139            [-1, 24, 8, 16]              48\n",
      "          Conv2d-140            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-141            [-1, 24, 8, 16]              48\n",
      "            ReLU-142            [-1, 24, 8, 16]               0\n",
      "InvertedResidual-143            [-1, 48, 8, 16]               0\n",
      "          Conv2d-144            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-145            [-1, 24, 8, 16]              48\n",
      "            ReLU-146            [-1, 24, 8, 16]               0\n",
      "          Conv2d-147            [-1, 24, 8, 16]             216\n",
      "     BatchNorm2d-148            [-1, 24, 8, 16]              48\n",
      "          Conv2d-149            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-150            [-1, 24, 8, 16]              48\n",
      "            ReLU-151            [-1, 24, 8, 16]               0\n",
      "InvertedResidual-152            [-1, 48, 8, 16]               0\n",
      "          Conv2d-153            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-154            [-1, 24, 8, 16]              48\n",
      "            ReLU-155            [-1, 24, 8, 16]               0\n",
      "          Conv2d-156            [-1, 24, 8, 16]             216\n",
      "     BatchNorm2d-157            [-1, 24, 8, 16]              48\n",
      "          Conv2d-158            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-159            [-1, 24, 8, 16]              48\n",
      "            ReLU-160            [-1, 24, 8, 16]               0\n",
      "InvertedResidual-161            [-1, 48, 8, 16]               0\n",
      "          Conv2d-162            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-163            [-1, 24, 8, 16]              48\n",
      "            ReLU-164            [-1, 24, 8, 16]               0\n",
      "          Conv2d-165            [-1, 24, 8, 16]             216\n",
      "     BatchNorm2d-166            [-1, 24, 8, 16]              48\n",
      "          Conv2d-167            [-1, 24, 8, 16]             576\n",
      "     BatchNorm2d-168            [-1, 24, 8, 16]              48\n",
      "            ReLU-169            [-1, 24, 8, 16]               0\n",
      "InvertedResidual-170            [-1, 48, 8, 16]               0\n",
      "          Conv2d-171             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-172             [-1, 48, 4, 8]              96\n",
      "          Conv2d-173             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-174             [-1, 48, 4, 8]              96\n",
      "            ReLU-175             [-1, 48, 4, 8]               0\n",
      "          Conv2d-176            [-1, 48, 8, 16]           2,304\n",
      "     BatchNorm2d-177            [-1, 48, 8, 16]              96\n",
      "            ReLU-178            [-1, 48, 8, 16]               0\n",
      "          Conv2d-179             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-180             [-1, 48, 4, 8]              96\n",
      "          Conv2d-181             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-182             [-1, 48, 4, 8]              96\n",
      "            ReLU-183             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-184             [-1, 96, 4, 8]               0\n",
      "          Conv2d-185             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-186             [-1, 48, 4, 8]              96\n",
      "            ReLU-187             [-1, 48, 4, 8]               0\n",
      "          Conv2d-188             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-189             [-1, 48, 4, 8]              96\n",
      "          Conv2d-190             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-191             [-1, 48, 4, 8]              96\n",
      "            ReLU-192             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-193             [-1, 96, 4, 8]               0\n",
      "          Conv2d-194             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-195             [-1, 48, 4, 8]              96\n",
      "            ReLU-196             [-1, 48, 4, 8]               0\n",
      "          Conv2d-197             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-198             [-1, 48, 4, 8]              96\n",
      "          Conv2d-199             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-200             [-1, 48, 4, 8]              96\n",
      "            ReLU-201             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-202             [-1, 96, 4, 8]               0\n",
      "          Conv2d-203             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-204             [-1, 48, 4, 8]              96\n",
      "            ReLU-205             [-1, 48, 4, 8]               0\n",
      "          Conv2d-206             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-207             [-1, 48, 4, 8]              96\n",
      "          Conv2d-208             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-209             [-1, 48, 4, 8]              96\n",
      "            ReLU-210             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-211             [-1, 96, 4, 8]               0\n",
      "          Conv2d-212             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-213             [-1, 48, 4, 8]              96\n",
      "            ReLU-214             [-1, 48, 4, 8]               0\n",
      "          Conv2d-215             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-216             [-1, 48, 4, 8]              96\n",
      "          Conv2d-217             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-218             [-1, 48, 4, 8]              96\n",
      "            ReLU-219             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-220             [-1, 96, 4, 8]               0\n",
      "          Conv2d-221             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-222             [-1, 48, 4, 8]              96\n",
      "            ReLU-223             [-1, 48, 4, 8]               0\n",
      "          Conv2d-224             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-225             [-1, 48, 4, 8]              96\n",
      "          Conv2d-226             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-227             [-1, 48, 4, 8]              96\n",
      "            ReLU-228             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-229             [-1, 96, 4, 8]               0\n",
      "          Conv2d-230             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-231             [-1, 48, 4, 8]              96\n",
      "            ReLU-232             [-1, 48, 4, 8]               0\n",
      "          Conv2d-233             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-234             [-1, 48, 4, 8]              96\n",
      "          Conv2d-235             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-236             [-1, 48, 4, 8]              96\n",
      "            ReLU-237             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-238             [-1, 96, 4, 8]               0\n",
      "          Conv2d-239             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-240             [-1, 48, 4, 8]              96\n",
      "            ReLU-241             [-1, 48, 4, 8]               0\n",
      "          Conv2d-242             [-1, 48, 4, 8]             432\n",
      "     BatchNorm2d-243             [-1, 48, 4, 8]              96\n",
      "          Conv2d-244             [-1, 48, 4, 8]           2,304\n",
      "     BatchNorm2d-245             [-1, 48, 4, 8]              96\n",
      "            ReLU-246             [-1, 48, 4, 8]               0\n",
      "InvertedResidual-247             [-1, 96, 4, 8]               0\n",
      "AdaptiveAvgPool2d-248             [-1, 96, 1, 1]               0\n",
      "          Linear-249                    [-1, 8]             776\n",
      "================================================================\n",
      "Total params: 107,266\n",
      "Trainable params: 107,266\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 8.03\n",
      "Params size (MB): 0.41\n",
      "Estimated Total Size (MB): 8.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from FD_MCSFANC_CNN_Model import Modified_ShufflenetV2_Frequency_DOA\n",
    "\n",
    "model = Modified_ShufflenetV2_Frequency_DOA(num_classes1=7, num_classes2=8).to(\"cuda\")\n",
    "print(model) # model components\n",
    "summary(model, (8, 64, 126)) # model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fcce3-731f-48b8-9954-542ddda17f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  107.27 K\n",
      "fwd MACs:                                                               7.44 MMACs\n",
      "fwd FLOPs:                                                              15.94 MFLOPS\n",
      "fwd+bwd MACs:                                                           22.32 MMACs\n",
      "fwd+bwd FLOPs:                                                          47.81 MFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "Modified_ShufflenetV2_Frequency_DOA(\n",
      "  107.27 K = 100% Params, 7.44 MMACs = 100% MACs, 15.94 MFLOPS = 46.67% FLOPs\n",
      "  (bw2col): Sequential(\n",
      "    139 = 0.13% Params, 887.04 KMACs = 11.92% MACs, 2.11 MFLOPS = 5.57% FLOPs\n",
      "    (0): BatchNorm2d(16 = 0.01% Params, 0 MACs = 0% MACs, 129.02 KFLOPS = 0% FLOPs, 8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): Conv2d(90 = 0.08% Params, 645.12 KMACs = 8.67% MACs, 1.37 MFLOPS = 4.05% FLOPs, 8, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 80.64 KFLOPS = 0% FLOPs)\n",
      "    (3): Conv2d(33 = 0.03% Params, 241.92 KMACs = 3.25% MACs, 508.03 KFLOPS = 1.52% FLOPs, 10, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (4): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 24.19 KFLOPS = 0% FLOPs)\n",
      "  )\n",
      "  (mv2_base_conv1): Sequential(\n",
      "    696 = 0.65% Params, 1.31 MMACs = 17.56% MACs, 2.76 MFLOPS = 8.2% FLOPs\n",
      "    (0): Conv2d(648 = 0.6% Params, 1.31 MMACs = 17.56% MACs, 2.61 MFLOPS = 8.2% FLOPs, 3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 96.77 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 48.38 KFLOPS = 0% FLOPs, inplace=True)\n",
      "  )\n",
      "  (mv2_base_maxpool): MaxPool2d(0 = 0% Params, 0 MACs = 0% MACs, 48.38 KFLOPS = 0% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (mv2_base_fre_stage2): Sequential(\n",
      "    6.94 K = 6.47% Params, 1.02 MMACs = 13.75% MACs, 2.19 MFLOPS = 6.42% FLOPs\n",
      "    (0): InvertedResidual(\n",
      "      2.4 K = 2.24% Params, 497.66 KMACs = 6.69% MACs, 1.06 MFLOPS = 3.12% FLOPs\n",
      "      (branch1): Sequential(\n",
      "        888 = 0.83% Params, 101.38 KMACs = 1.36% MACs, 218.11 KFLOPS = 0.64% FLOPs\n",
      "        (0): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 396.29 KMACs = 5.33% MACs, 844.8 KFLOPS = 2.49% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 294.91 KMACs = 3.96% MACs, 589.82 KFLOPS = 1.85% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 24.58 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 12.29 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mv2_base_fre_stage3): Sequential(\n",
      "    45.55 K = 42.47% Params, 1.6 MMACs = 21.5% MACs, 3.32 MFLOPS = 10.03% FLOPs\n",
      "    (0): InvertedResidual(\n",
      "      8.26 K = 7.7% Params, 470.02 KMACs = 6.32% MACs, 973.82 KFLOPS = 2.95% FLOPs\n",
      "      (branch1): Sequential(\n",
      "        2.93 K = 2.73% Params, 87.55 KMACs = 1.18% MACs, 182.78 KFLOPS = 0.55% FLOPs\n",
      "        (0): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 382.46 KMACs = 5.14% MACs, 791.04 KFLOPS = 2.4% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 294.91 KMACs = 3.96% MACs, 589.82 KFLOPS = 1.85% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 12.29 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mv2_base_doa_stage2): Sequential(\n",
      "    6.94 K = 6.47% Params, 1.02 MMACs = 13.75% MACs, 2.19 MFLOPS = 6.42% FLOPs\n",
      "    (0): InvertedResidual(\n",
      "      2.4 K = 2.24% Params, 497.66 KMACs = 6.69% MACs, 1.06 MFLOPS = 3.12% FLOPs\n",
      "      (branch1): Sequential(\n",
      "        888 = 0.83% Params, 101.38 KMACs = 1.36% MACs, 218.11 KFLOPS = 0.64% FLOPs\n",
      "        (0): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 396.29 KMACs = 5.33% MACs, 844.8 KFLOPS = 2.49% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 294.91 KMACs = 3.96% MACs, 589.82 KFLOPS = 1.85% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 24.58 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 12.29 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        1.51 K = 1.41% Params, 175.1 KMACs = 2.35% MACs, 374.78 KFLOPS = 1.1% FLOPs\n",
      "        (0): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(216 = 0.2% Params, 27.65 KMACs = 0.37% MACs, 55.3 KFLOPS = 0.17% FLOPs, 24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "        (4): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(576 = 0.54% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(48 = 0.04% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mv2_base_doa_stage3): Sequential(\n",
      "    45.55 K = 42.47% Params, 1.6 MMACs = 21.5% MACs, 3.32 MFLOPS = 10.03% FLOPs\n",
      "    (0): InvertedResidual(\n",
      "      8.26 K = 7.7% Params, 470.02 KMACs = 6.32% MACs, 973.82 KFLOPS = 2.95% FLOPs\n",
      "      (branch1): Sequential(\n",
      "        2.93 K = 2.73% Params, 87.55 KMACs = 1.18% MACs, 182.78 KFLOPS = 0.55% FLOPs\n",
      "        (0): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 382.46 KMACs = 5.14% MACs, 791.04 KFLOPS = 2.4% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 294.91 KMACs = 3.96% MACs, 589.82 KFLOPS = 1.85% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 12.29 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 6.14 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "      (branch1): Sequential(0 = 0% Params, 0 MACs = 0% MACs, 0 FLOPS = 0% FLOPs)\n",
      "      (branch2): Sequential(\n",
      "        5.33 K = 4.97% Params, 161.28 KMACs = 2.17% MACs, 334.85 KFLOPS = 1.01% FLOPs\n",
      "        (0): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "        (3): Conv2d(432 = 0.4% Params, 13.82 KMACs = 0.19% MACs, 27.65 KFLOPS = 0.09% FLOPs, 48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "        (4): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(2.3 K = 2.15% Params, 73.73 KMACs = 0.99% MACs, 147.46 KFLOPS = 0.46% FLOPs, 48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(96 = 0.09% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.54 KFLOPS = 0% FLOPs, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avg_pool_fre): AdaptiveAvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, output_size=(1, 1))\n",
      "  (avg_pool_doa): AdaptiveAvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 3.07 KFLOPS = 0% FLOPs, output_size=(1, 1))\n",
      "  (freq_fc): Linear(679 = 0.63% Params, 672 MACs = 0.01% MACs, 1.34 KFLOPS = 0% FLOPs, in_features=96, out_features=7, bias=True)\n",
      "  (doa_fc): Linear(776 = 0.72% Params, 768 MACs = 0.01% MACs, 1.54 KFLOPS = 0% FLOPs, in_features=96, out_features=8, bias=True)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Model FLOPs:15.94 MFLOPS   MACs:7.44 MMACs   Params:107.27 K \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MACs and Flops\n",
    "\n",
    "import torch\n",
    "from calflops import calculate_flops\n",
    "\n",
    "from FD_MCSFANC_CNN_Model import Modified_ShufflenetV2_Frequency_DOA\n",
    "model = Modified_ShufflenetV2_Frequency_DOA(num_classes1=7, num_classes2=8).to(\"cuda\")\n",
    "model.eval()\n",
    "input_shape = (1, 8, 64, 126)\n",
    "\n",
    "flops, macs, params = calculate_flops(model=model, \n",
    "                                      input_shape=input_shape,\n",
    "                                      output_as_string=True,\n",
    "                                      output_precision=2)\n",
    "print(\"Model FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))\n",
    "\n",
    "# \"FLOPs\"关注于单个计算任务的复杂度，而\"FLOPS\"关注于计算设备的处理速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999abaa1-3893-4ba5-8535-ddeb40e4a4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the model: 8.52 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Running time\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from FD_MCSFANC_CNN_Model import Modified_ShufflenetV2_Frequency_DOA\n",
    "model = Modified_ShufflenetV2_Frequency_DOA(num_classes1=7, num_classes2=8)\n",
    "model.eval()\n",
    "input = torch.randn(1, 8, 64, 126)\n",
    "\n",
    "for _ in range(10):\n",
    "    model(input)\n",
    "start_time = time.perf_counter()\n",
    "output = model(input)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "# Total running time for 0.5 second input\n",
    "runtime_ms = (end_time - start_time) * 1000  # 将秒转换为毫秒\n",
    "print(f\"Runtime of the model: {runtime_ms:.2f} milliseconds\")\n",
    "# Runtime of the model: 8.52 milliseconds cpu比gpu快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14924f04-45fe-41d5-ba73-6a60ec272cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
